---
title: "787 Assignment 2"
author: "Zach Gagnon"
date: 2023-03-10
slug: []
categories: []
tags: []
---



## Exercise 1

The following R chunk loads the data for the closing prices of nine major tech companies over the last ten years, and plots them as time series.


```r
setwd("C:/Users/16317/Documents/Spring 2023/STAT 787/Assignment 2")

close <- read.csv("ClosingPrices.csv")
head(close)
```

```
##       Date     AAPL    AMZN     GOOG      IBM  INTC  META  MSFT   NVDA  ORCL
## 1 2/1/2013 16.20071 13.2500 19.31759 196.1568 21.36 29.73 27.93 3.0925 36.21
## 2 2/4/2013 15.79714 12.9990 18.90464 194.8279 21.16 28.11 27.44 3.0400 35.13
## 3 2/5/2013 16.35143 13.3445 19.07201 193.8719 21.18 28.64 27.50 3.1100 35.48
## 4 2/6/2013 16.33393 13.1110 19.18235 192.1797 20.99 29.05 27.34 3.0850 35.10
## 5 2/7/2013 16.72214 13.0115 19.27650 190.9560 20.81 28.65 27.28 3.0725 34.56
## 6 2/8/2013 16.96357 13.0975 19.56093 192.8107 21.00 28.55 27.55 3.0925 34.90
```

```r
close$Date <-  as.Date(close$Date, "%m/%d/%Y")

par(mfrow=c(3,3))
plot(close$AAPL ~ close$Date, xlab="AAPL", ylab="Closing Price")
plot(close$AMZN ~ close$Date, xlab="AMZN", ylab="Closing Price")
plot(close$GOOG ~ close$Date, xlab="GOOG", ylab="Closing Price")
plot(close$IBM ~ close$Date, xlab="IBM", ylab="Closing Price")
plot(close$INTC ~ close$Date, xlab="INTC", ylab="Closing Price")
plot(close$META ~ close$Date, xlab="META", ylab="Closing Price")
plot(close$MSFT ~ close$Date, xlab="MSFT", ylab="Closing Price")
plot(close$NVDA ~ close$Date, xlab="NVDA", ylab="Closing Price")
plot(close$ORCL ~ close$Date, xlab="ORCL", ylab="Closing Price")
```

<img src="index.2_files/figure-html/unnamed-chunk-1-1.png" width="672" />

The same plotting will be done again, but using ggplot.


```r
library(ggplot2)
library(dplyr)
```

```
## 
## Attaching package: 'dplyr'
```

```
## The following objects are masked from 'package:stats':
## 
##     filter, lag
```

```
## The following objects are masked from 'package:base':
## 
##     intersect, setdiff, setequal, union
```

```r
p1 <- ggplot(close, aes(x=Date, y=AAPL)) + geom_line() + xlab("AAPL") + ylab("Closing Price")
p2 <- ggplot(close, aes(x=Date, y=AMZN)) + geom_line() + xlab("AMZN") + ylab("Closing Price")
p3 <- ggplot(close, aes(x=Date, y=GOOG)) + geom_line() + xlab("GOOG") + ylab("Closing Price")
p4 <- ggplot(close, aes(x=Date, y=IBM)) + geom_line() + xlab("IBM") + ylab("Closing Price")
p5 <- ggplot(close, aes(x=Date, y=INTC)) + geom_line() + xlab("INTC") + ylab("Closing Price")
p6 <- ggplot(close, aes(x=Date, y=META)) + geom_line() + xlab("META") + ylab("Closing Price")
p7 <- ggplot(close, aes(x=Date, y=MSFT)) + geom_line() + xlab("MSFT") + ylab("Closing Price")
p8 <- ggplot(close, aes(x=Date, y=NVDA)) + geom_line() + xlab("NVDA") + ylab("Closing Price")
p9 <- ggplot(close, aes(x=Date, y=ORCL)) + geom_line() + xlab("ORCL") + ylab("Closing Price")
library(patchwork)
p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8 + p9
```

<img src="index.2_files/figure-html/unnamed-chunk-2-1.png" width="672" />

We can see from both plots above that Apple, Amazon, Google, Meta, Microsoft, Nividia, and Oracle all have similar trends. From 2013 until 2022 we see an exponential increase in closing price, but then a decrease in 2023. Note that we see a big jump after 2020 with this companies, probably due to the Covid-19 pandemic. As for IBM, it appears their stock has decreased somewhat steadily over the last decade. Intel's stock increases in what appears to be a linear trend over from 2013 to 2021, and then took a major dip over the last two years.

The following R chunks plot the time series seen above on one plot. The first chunk does so with traditional plotting and the second with ggplot.


```r
par(mfrow=c(1,1))
plot(close$AAPL ~ close$Date, type="l", col=2, xlab="Date", ylab="Closing Price", 
     ylim=c(0,400))
lines(close$AMZN ~ close$Date, type="l", col=3)
lines(close$GOOG ~ close$Date, type="l", col=4)
lines(close$IBM ~ close$Date, type="l", col=5)
lines(close$INTC ~ close$Date, type="l", col=6)
lines(close$META ~ close$Date, type="l", col=7)
lines(close$MSFT ~ close$Date, type="l", col=8)
lines(close$NVDA ~ close$Date, type="l", col=9)
lines(close$ORCL ~ close$Date, type="l", col=10)
legend("topleft", c("AAPL", "AMZN", "GOOG", "IBM", "INTC", "META", "MSFT", "NVDA", "ORCL"), 
       cex=0.70, fill=2:10)
```

<img src="index.2_files/figure-html/unnamed-chunk-3-1.png" width="672" />


```r
library(reshape2)
meltdf <- melt(close, id="Date")

ggplot(meltdf, aes(x=Date,  y=value, colour=variable, group=variable)) +
  geom_line() + ylab("Closing Price")
```

<img src="index.2_files/figure-html/unnamed-chunk-4-1.png" width="672" />

## Exercise 2

Using the R data set mtcars, ten linear learners were built using bootstrap samples of the data.


```r
data(mtcars)
mtcars
```

```
##                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb
## Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4
## Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1
## Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1
## Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2
## Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1
## Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4
## Merc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2
## Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2
## Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4
## Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4
## Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3
## Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3
## Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3
## Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4
## Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4
## Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4
## Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1
## Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2
## Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1
## Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1
## Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2
## AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2
## Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4
## Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2
## Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1
## Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2
## Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2
## Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4
## Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6
## Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8
## Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2
```

```r
L <- 10
n <- nrow(mtcars)
models <- list()

for(i in 1:L)
{
  boot <- mtcars[sample(n, replace=T),]
  learner <- lm(mpg ~ ., data=boot)
  models[[i]] <- learner
}
models
```

```
## [[1]]
## 
## Call:
## lm(formula = mpg ~ ., data = boot)
## 
## Coefficients:
## (Intercept)          cyl         disp           hp         drat           wt  
##    44.07402     -3.10559      0.05296     -0.02170     -1.46712     -7.43073  
##        qsec           vs           am         gear         carb  
##     1.07775     -3.55518      3.10713     -1.76923      1.09063  
## 
## 
## [[2]]
## 
## Call:
## lm(formula = mpg ~ ., data = boot)
## 
## Coefficients:
## (Intercept)          cyl         disp           hp         drat           wt  
##   -1.904306     0.002641     0.040962    -0.031425     1.307007    -5.137662  
##        qsec           vs           am         gear         carb  
##    1.039009     0.382645     2.200756     2.680860    -0.173122  
## 
## 
## [[3]]
## 
## Call:
## lm(formula = mpg ~ ., data = boot)
## 
## Coefficients:
## (Intercept)          cyl         disp           hp         drat           wt  
##  -23.553577     3.162165    -0.006798    -0.033946     5.520707     0.177735  
##        qsec           vs           am         gear         carb  
##   -0.232216     7.609139     0.980413     4.369456    -1.502908  
## 
## 
## [[4]]
## 
## Call:
## lm(formula = mpg ~ ., data = boot)
## 
## Coefficients:
## (Intercept)          cyl         disp           hp         drat           wt  
##   -15.33023      0.83099      0.02524     -0.04172      2.78979     -5.92026  
##        qsec           vs           am         gear         carb  
##     1.76560     -1.04891     -0.19495      2.19586      0.36033  
## 
## 
## [[5]]
## 
## Call:
## lm(formula = mpg ~ ., data = boot)
## 
## Coefficients:
## (Intercept)          cyl         disp           hp         drat           wt  
##   25.120166    -0.369941    -0.009786     0.002511    -0.407381    -2.059182  
##        qsec           vs           am         gear         carb  
##    0.522217     2.062374     5.668586    -0.831481    -0.729883  
## 
## 
## [[6]]
## 
## Call:
## lm(formula = mpg ~ ., data = boot)
## 
## Coefficients:
## (Intercept)          cyl         disp           hp         drat           wt  
##    16.96228     -0.97197      0.02077     -0.03948      0.88661     -1.58088  
##        qsec           vs           am         gear         carb  
##     0.56021      0.41479      3.82047     -0.21993      0.48482  
## 
## 
## [[7]]
## 
## Call:
## lm(formula = mpg ~ ., data = boot)
## 
## Coefficients:
## (Intercept)          cyl         disp           hp         drat           wt  
##     9.71298      0.07116      0.02692     -0.03368      2.33525     -4.03700  
##        qsec           vs           am         gear         carb  
##     0.09738      2.03233     -1.49243      3.09429     -0.18773  
## 
## 
## [[8]]
## 
## Call:
## lm(formula = mpg ~ ., data = boot)
## 
## Coefficients:
## (Intercept)          cyl         disp           hp         drat           wt  
##   -95.57695      2.10603      0.04337      0.02848      4.37686     -7.78312  
##        qsec           vs           am         gear         carb  
##     4.03336      0.55017     -0.93513      7.59544     -0.49264  
## 
## 
## [[9]]
## 
## Call:
## lm(formula = mpg ~ ., data = boot)
## 
## Coefficients:
## (Intercept)          cyl         disp           hp         drat           wt  
##   24.081626     0.347983     0.001894    -0.035819    -0.238993    -2.539044  
##        qsec           vs           am         gear         carb  
##    0.232535    -0.259687     0.932861     1.575581    -0.892403  
## 
## 
## [[10]]
## 
## Call:
## lm(formula = mpg ~ ., data = boot)
## 
## Coefficients:
## (Intercept)          cyl         disp           hp         drat           wt  
##  -52.532910     1.234547     0.007127     0.013299     4.516364    -3.435884  
##        qsec           vs           am         gear         carb  
##    2.331795    -3.453283    -0.833376     6.386921    -2.122007
```

Then, a matrix is created to store the coefficients and MSE of each model. From this matrix, the "average" model is calculated along with its MSE.


```r
models.mat <- matrix(NA, nrow=L, ncol=12)
for(i in 1:L)
{
  models.mat[i,] <- c(models[[i]]$coefficients, mean((models[[i]]$residuals)^2))
}

fhat.avg <- c()
for(i in 1:12)
{
  avg <- mean(models.mat[,i])
  fhat.avg <- c(fhat.avg, avg)
}

singular <- lm(mpg ~ ., data=mtcars)
compare <- matrix(NA, nrow=2, ncol=12)
compare[1,] <- fhat.avg
compare[2,] <- c(singular$coefficients, mean((singular$residuals)^2))
compare
```

```
##          [,1]       [,2]       [,3]        [,4]     [,5]      [,6]      [,7]
## [1,] -6.89469  0.3308014 0.02026727 -0.01934780 1.961909 -3.974604 1.1427631
## [2,] 12.30337 -0.1114405 0.01333524 -0.02148212 0.787111 -3.715304 0.8210407
##           [,8]     [,9]    [,10]      [,11]    [,12]
## [1,] 0.4734392 1.325432 2.507776 -0.4164902 2.688050
## [2,] 0.3177628 2.520227 0.655413 -0.1994193 4.609201
```

The first row of the matrix compare seen above contains the coefficients and MSE of the average model, while the second row contains that of the singular linear model. Comparing the two, we can see that most of the coefficient are quite similar, but the MSE of the average model shows that it performs better than the singular model.

## Exercise 3

The following data set contains the coordinates of the countries of Europe. From this data,  dendrograms are plotted of four different hierarchical clustering of the manhattan distances between countries. Single, double, average, and Ward D2 clustering were used.







